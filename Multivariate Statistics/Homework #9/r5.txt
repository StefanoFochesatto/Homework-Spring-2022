## Data From March Handout

prob3_data <- structure(list(group = c(rep(1,30),rep(2,30),rep(3,50)), 
x = c(21.45, 21.98, 20.42, 21.75, 20.49, 21.6, 18.15, 18.82, 17.53, 20.24, 
      19.82, 16.76, 21.74, 18.83, 20.66, 18.13, 17.79, 17.2, 18.19, 19.67, 
      20.94, 22.61, 23.59, 21.23, 18.98, 24.56, 19.72, 21.48, 19.62, 21.22, 
      23.81, 23.74, 24.91, 21.87, 23.59, 22.29, 22.2, 24.61, 22.23, 23.11, 
      22.14, 22.75, 22.81, 22.94, 23.62, 24.04, 21.42, 22.37, 22.04, 21.98, 
      24.64, 21.88, 22.87, 24.43, 22.65, 22.84, 25.07, 24.71, 20.49, 21.56, 
      16.85, 17.3, 17.59, 20.63, 18.35, 18.33, 11.46, 15.39, 17.61, 19.83, 
      14.71, 14.46, 11.39, 8.98, 14.13, 19.19, 18.45, 18.94, 19.65, 20.18, 19.36,
      17.25, 19.89, 13.22, 17.67, 14.89, 15.36, 22.8, 16.89, 20.34, 14.84, 19.41, 
      15.92, 18.45, 22.82, 16.44, 20.12, 12.68, 14.26, 17.41, 17.75, 11.42, 17.98, 
      16.14, 17.67, 16.33, 22.48, 20.58, 17.85, 16.18), 

y = c(11.29, 14.06, 14.59, 15.68, 17.44, 12.37, 12.29, 16.6, 14.76, 12.69, 
      19.11, 11.88, 16.01, 18, 15.21, 12.7, 13.59, 16.09, 15.26, 11.22, 18.08,
      13.15, 13.55, 17.45, 18.79, 11.66, 16.49, 12.99, 12.67, 13.22, 11.15, 12.85, 
      11.39, 10.99, 10.47, 12.72, 10.89, 5.58, 12.45, 9.19, 11.98, 11.04, 12.64,
      7.41, 13.27, 15.05, 12.68, 12.9, 6.6, 13.05, 10.93, 14.6, 10.82, 8.38, 13.04,
      12.07, 14.91, 12.23, 10.1, 13.74, 17.5, 18.87, 19.05, 16.85, 18.77, 18.18, 
      19.21, 18.76, 19.07, 17.7, 19.95, 16.31, 16.63, 15.91, 17.62, 18.81, 16.8, 
      17.47, 16.34, 18.65, 17.42, 17.42, 19.2, 17.22, 20.08, 19.39, 19.31, 17.18, 
      19.9, 19.51, 18.33, 18.54, 17.81, 17.58, 19.24, 18.54, 18.78, 17.15, 19.23, 
      18.49, 18.71, 20.52, 16.61, 17.71, 19, 18.41, 18.64, 17.41, 18.8, 17.87)), 
      class ="data.frame", row.names = c(NA, -110L))


## Training on 60% of the data with proportional priors
# > (50/110)*66
#   [1] 30
# > (30/110)*66
#   [1] 18
# > 18 + 18 + 30
#   [1] 66


## Sampling and Splitting the data
train_index <- c(sample(1:30, size=18, replace=FALSE), 
                 sample(31:60, size=18, replace=FALSE), 
                 sample(61:110, size=30, replace=FALSE))

train <- prob3_data[train_index,]
test <- prob3_data[-train_index,]

## Fitting Multinomial Logistic Regression (nnet package)
MultinomialLogRegression <- multinom(group ~ ., data = train)

## Making predictions from test data
testPrediction <- predict(MultinomialLogRegression,
                          newdata=data.frame(test[,2:3]))

## Generating Confusion Matrix
confusionMatrix(testPrediction,as.factor(test[,1]))
_____________________________________________________________________
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction  1  2  3
##          1  7  3  4
##          2  3  9  0
##          3  2  0 16
## 
## Overall Statistics
##                                           
##                Accuracy : 0.7273          
##                  95% CI : (0.5721, 0.8504)
##     No Information Rate : 0.4545          
##     P-Value [Acc > NIR] : 0.0002273       
##                                           
##                   Kappa : 0.5823          
##                                           
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: 1 Class: 2 Class: 3
## Sensitivity            0.5833   0.7500   0.8000
## Specificity            0.7812   0.9062   0.9167
## Pos Pred Value         0.5000   0.7500   0.8889
## Neg Pred Value         0.8333   0.9062   0.8462
## Prevalence             0.2727   0.2727   0.4545
## Detection Rate         0.1591   0.2045   0.3636
## Detection Prevalence   0.3182   0.2727   0.4091
## Balanced Accuracy      0.6823   0.8281   0.8583
_____________________________________________________________________

